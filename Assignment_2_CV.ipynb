{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Explain convolutional neural network, and how does it work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans-->CNN is a type of feed-forward artificial network where the connectivity pattern between its neurons is inspired by the organization of the animal visual cortex. The visual cortex has a small region of cells that are sensitive to specific regions of the visual field."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. How does refactoring parts of your neural network definition favor you?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans--> Refactoring is the process of restructuring code, while not changing its original functionality. The goal of refactoring is to improve internal code by making many small changes without altering the code's external behavior. Refactoring improves code readability and reduces complexities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. What does it mean to flatten? Is it necessary to include it in the MNIST CNN? What is the reason for this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans-->The process of converting all the resultant 2-d arrays into a vector is called Flattening.\n",
    "Flattening is used to convert all the resultant 2-Dimensional arrays from pooled feature maps into a single long continuous linear vector. The flattened matrix is fed as input to the fully connected layer to classify the image.\n",
    "Flattening is mostly done to put data in a format that a relational data warehouse can use natively, and make sure queries perform well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. What exactly does NCHW stand for?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans--> NCHW stands for: batch N, channels C, depth D, height H, width W."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Why are there 7*7*(1168-16) multiplications in the MNIST CNN's third layer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans--> There is 1 bias for each channel. The output shape is 64X4X14X14 and this will therefore become the input shape to the next layer. The next layer has 296 parameters. So for each 196 location we are multiplying 296-8=288 weights so that 196*288 = 56_448 multiplication at this layer. The next layer will have 7*7*(1168-16) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.Explain definition of  receptive field?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans-->Receptive field: A specific region of sensory space in which an appropriate stimulus can drive an electrical response in a sensory neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. What is the scale of an activation's receptive field after two stride-2 convolutions? What is the reason for this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans--> In above case of a kernel with dimensions 3x3, the adoption of a stride of 2 results in one column or one row overlapping with adjacent receptive fields. This overlap is desired to guarantee that the stride doesnâ€™t skip important information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. What is the tensor representation of a color image?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans-->If the image tensors encode an RGB image, then each pixel contains three values i.e., the intensities of the red, green, and blue sub-pixels. If the image tensor is of type Int32 , the value [0, 0, 0] encodes the color black and the value [255, 255, 255] encodes the color white."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. How does a color input interact with a convolution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans--> To perform a convolution of this kernel with the given grayscale image, we center our kernel over the pixels of the image, and take each corresponding pixel and kernel value, multiply them together, sum the whole thing up, and then assign it to the corresponding pixel in the convoluted image."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
